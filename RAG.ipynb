{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "\n",
    "API_SECRET_KEY = \"sk-fQmZ27DLJestJOeZ915dEbA0325d47AaAc86B6Ed609625E5\"\n",
    "BASE_URL = \"https://api.gpts.vin/v1\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_SECRET_KEY\n",
    "os.environ[\"OPENAI_API_BASE\"] = BASE_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_community.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Document Preparation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader1 = PyPDFLoader(\"围棋史话.pdf\")\n",
    "loader2 = PyPDFLoader(\"围棋高手.pdf\")\n",
    "loader3 = PyPDFLoader(\"围棋历史对决.pdf\")\n",
    "go_history_books = loader1.load()\n",
    "go_masters_players = loader2.load()\n",
    "go_classic_matches = loader3.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web crawler to get real-time match information\n",
    "def get_game_data(page):\n",
    "    url = f\"https://www.19x19.com/api/engine/games/0086-golaxy_public?page={page}&size=7&game_type=2&username=0086-golaxy_public\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get('data', {}).get('gameMetaList', [])\n",
    "    else:\n",
    "        print(\"获取数据失败。\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_game_info(game):\n",
    "    create_date = game.get(\"createTime\", {}).get(\"date\", {})\n",
    "    play_date = game.get(\"playTime\", {}).get(\"date\", {})\n",
    "    analyze_date = game.get(\"analyzeTime\", {}).get(\"date\", {})\n",
    "\n",
    "    create_date_str = f\"{create_date.get('year', '')}-{create_date.get('month', '')}-{create_date.get('day', '')}\"\n",
    "    play_date_str = f\"{play_date.get('year', '')}-{play_date.get('month', '')}-{play_date.get('day', '')}\"\n",
    "    analyze_date_str = f\"{analyze_date.get('year', '')}-{analyze_date.get('month', '')}-{analyze_date.get('day', '')}\"\n",
    "\n",
    "    # Deal with the information\n",
    "    game_result = game.get(\"gameResult\", \"\")\n",
    "    if \"W+R\" in game_result:\n",
    "        game_result = \"白方胜利\"\n",
    "    elif \"B+R\" in game_result:\n",
    "        game_result = \"黑方胜利\"\n",
    "    else:\n",
    "        game_result = \"未知\"\n",
    "\n",
    "    game_info = {\n",
    "        \"对局名称\": game.get(\"gamename\", \"\"),\n",
    "        \"黑方选手\": game.get(\"pb\", \"\"),\n",
    "        \"白方选手\": game.get(\"pw\", \"\"),\n",
    "        \"黑方段位\": game.get(\"pbLevel\", \"\"),\n",
    "        \"白方段位\": game.get(\"pwLevel\", \"\"),\n",
    "        \"起始手数\": game.get(\"startMoveNum\", 0),\n",
    "        \"总手数\": game.get(\"moveNum\", 0),\n",
    "        \"棋盘大小\": game.get(\"boardSize\", 0),\n",
    "        \"规则\": game.get(\"rule\", \"\"),\n",
    "        \"贴目\": game.get(\"komi\", 0),\n",
    "        \"让子数\": game.get(\"handicap\", 0),\n",
    "        \"对局结果\": game_result,\n",
    "        \"分析状态\": game.get(\"analyzeStatus\", \"\"),\n",
    "        \"分析点数\": game.get(\"analyzePo\", 0),\n",
    "        \"创建时间\": create_date_str,\n",
    "        \"对局时间\": play_date_str,\n",
    "        \"分析时间\": analyze_date_str,\n",
    "    }\n",
    "    return game_info\n",
    "\n",
    "\n",
    "def get_current_go_match(start_page, end_page):\n",
    "    all_game_info_list = []\n",
    "    for page_number in range(start_page - 1, end_page):\n",
    "        games = get_game_data(page_number)\n",
    "        if games:\n",
    "            game_info_list = [extract_game_info(game) for game in games]\n",
    "            all_game_info_list.extend(game_info_list)\n",
    "            print(f\"第{page_number + 1}页,数据：{game_info_list}。\")\n",
    "        else:\n",
    "            print(f\"第{page_number + 1}页未找到游戏数据。\\n\")\n",
    "\n",
    "    if all_game_info_list:\n",
    "        df = pd.DataFrame(all_game_info_list)\n",
    "        return df\n",
    "        # df.to_csv(f\"围棋对决数据{start_page}_{end_page}页.csv\", index=False)\n",
    "        # print(\"所有围棋对决数据已保存至 围棋对决数据.csv\\n\")\n",
    "    else:\n",
    "        print(\"没有找到任何围棋对决数据。\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = get_current_go_match(start_page=1, end_page=10)\n",
    "go_current_matches = DataFrameLoader(info, page_content_column=\"对局名称\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Save In VectorStores` (In this process contain `Embedding`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_function = HuggingFaceEmbeddings(model_name=\"aspire/acge_text_embedding\")\n",
    "# # sentences = [\"数据1\", \"数据2\"]\n",
    "\n",
    "# # embeddings_1 = model.encode(sentences, normalize_embeddings=True)\n",
    "# # embeddings_2 = model.encode(sentences, normalize_embeddings=True)\n",
    "# # similarity = embeddings_1 @ embeddings_2.T\n",
    "# # print(similarity)\n",
    "# vectorstore = Chroma.from_documents(documents=history_go_books, embedding=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Given the split doc then embedding them in the Vectorstorage/Graphicstorage\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_for_classic_match = Chroma.from_documents(documents=go_classic_matches, embedding=embedding_function)\n",
    "vectorstore_for_players = Chroma.from_documents(documents=go_masters_players, embedding=embedding_function)\n",
    "vectorstore_for_current_match = Chroma.from_documents(documents=go_current_matches, embedding=embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.load import dumps, loads\n",
    "from langchain_community.retrievers import BM25Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "判断两部棋子的时间是否过长，如果过长添加历史书籍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_history_knowladge = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Routing` to choose which retrieval method to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterQuery(BaseModel):\n",
    "    datasource: Literal[\"no_need_for_knowledge\", \"current_go_match_info\", \"go_classic_match\", \"go_masters\"] = Field(\n",
    "        description=\"Given a description of the Go board question choose which datasource would be most relevant for answering their question\"\n",
    "    )\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(RouterQuery)\n",
    "\n",
    "# Prompt for routing\n",
    "system = \"\"\"You are an expert at routing a user question to the appropriate data source.\n",
    "Based on the programming language the question is referring to, route it to the relevant data source.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{description}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define router\n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go board description\n",
    "description = \"\"\"从整体来看，黑棋在右上角和右下角的地盘较为稳固，形势较好;而白棋在左上角和中腹的形势较为复杂，尚不明朗。整体上，黑棋在地盘上略占优势。我们可以来关注一下现在其他场次的比赛情况\n",
    "\"\"\"\n",
    "\n",
    "routing_result = router.invoke({\"description\": description})\n",
    "routing_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not `Save In VectorStores`, no `Embedding`, directly use some character information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = BM25Retriever.from_documents(documents=go_classic_matches, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RAG-Fusion`(Query Translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG-Fusion to generate the similar queries for better retrieval\n",
    "template = \"\"\"Receive a description of the current Go board game, \n",
    "you need to judge whether you need Go-related questions based on your knowledge of Go, \n",
    "if not then you don't need to generate multiple query, \n",
    "if you do then you need to generate multiple query, the content of these query can be related to the three directions: the current situation of the Go game, the history of the classic Go game, and the history of the Go masters. \\n\n",
    "Judge whether generating multiple search queries related to: {description} \\n\n",
    "Output Example:\\n\n",
    "Q: \n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "prompt_query_translation = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "generate_multi_query = (\n",
    "    prompt_query_translation\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each query retrieval for couples of documents, then rank these documents according to the ranking score and delete overlap\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    '''\n",
    "        Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "            and an optional parameter k used in the RRF formula \n",
    "    ''' \n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create Retriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever for the Vectorstore\n",
    "def get_docs(retriever):\n",
    "    retrieval_chain_rag_fusion = (\n",
    "        generate_multi_query \n",
    "        | retriever.map() \n",
    "        | reciprocal_rank_fusion\n",
    "    )\n",
    "\n",
    "    docs = retrieval_chain_rag_fusion.invoke({\"description\": description})\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_select(routing_result):\n",
    "    if add_history_knowladge == True:\n",
    "        pass\n",
    "    else:\n",
    "        if routing_result.datasource == 'go_masters':\n",
    "            retriever = vectorstore_for_players.as_retriever(search_kwargs={\"k\": 5})\n",
    "            return get_docs(retriever=retriever)\n",
    "        elif routing_result.datasource ==  'go_classic_match':\n",
    "            retriever = vectorstore_for_classic_match.as_retriever(search_kwargs={\"k\": 5})\n",
    "            return get_docs(retriever=retriever)\n",
    "        elif routing_result.datasource == 'current_go_match_info':\n",
    "            retriever = vectorstore_for_current_match.as_retriever(search_kwargs={\"k\": 5})\n",
    "            return get_docs(retriever=retriever)\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = route_select(routing_result=routing_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final `Prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the context(RAG) and the question to generate a templete for prompt\n",
    "template = \"\"\"You will act as a Go commentator.\n",
    "I will provide you with the current state of the Go board, as well as some additional commentary, and you will need to reorganise the order of the words to produce an organised, clear commentary.\n",
    "Description of the current Go board situation: {descriptions}\n",
    "Some additional commentary: {context}\n",
    "All the replies are in Chinese, you just need to reply, not keep asking me questions:\n",
    "解说稿:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM specified\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "ans = chain.invoke({\"descriptions\":description, \"context\": docs})\n",
    "ans.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
